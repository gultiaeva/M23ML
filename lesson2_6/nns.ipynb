{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Нейронные сети",
   "id": "8b645aa64ce3697d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Полносвязные нейронные сети (FCNN)",
   "id": "d68dfc5615da604d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Одиночный нейрон (Перцептрон)\n",
    "\n",
    "Одиночный нейрон вычисляет взвешенную сумму его входов, добавляет свободный коэффициент (bias/смещение), а затем пропускает результат через функцию активации:\n",
    "\n",
    "$$y = \\phi\\bigl(\\mathbf{w}^\\top \\mathbf{x} + b\\bigr)$$\n",
    "* Веса $\\mathbf{w}$: взвешиватют каждый вход\n",
    "* Смещение $b$: смещает порог активации\n",
    "* Активация $\\phi(\\cdot)$: вводит нелинейность, позволяя сети учить сложные зависимости\n",
    "\n",
    "Популярные функции активации:\n",
    "* Пороговая: $\\phi(z)=\\begin{cases}1,&z\\ge0\\\\0,&z<0\\end{cases}$\n",
    "* Sigmoid: $\\phi(z)=\\frac{1}{1 + e^{-z}}$, outputs in (0,1)\n",
    "* Tanh: $\\phi(z)=\\tanh(z)$, outputs in (−1,1)\n",
    "* ReLU: $\\phi(z)=\\max(0,z)$, sparse activations, fast convergence\n",
    "* Leaky ReLU: $\\phi(z)=\\max(\\alpha z, z)$, alleviates “dead” neurons"
   ],
   "id": "8eb24db2bc3b3d4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "680ca820cdc6c251"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "id": "a188656f58f271f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "class SingleNeuron(nn.Module):\n",
    "    def __init__(self, in_features, activation='relu'):\n",
    "        super().__init__()\n",
    "        # Linear layer: one output neuron\n",
    "        self.linear = nn.Linear(in_features, 1)\n",
    "        # Select activation\n",
    "        activations = {\n",
    "            'step': lambda x: (x >= 0).float(),\n",
    "            'sigmoid': nn.Sigmoid(),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(negative_slope=0.01)\n",
    "        }\n",
    "        self.act = activations[activation]\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.linear(x)            # compute w·x + b\n",
    "        return self.act(z)            # apply chosen activation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "model = SingleNeuron(in_features=10, activation='sigmoid')\n",
    "output = model(torch.randn(5, 10))  # batch of 5 samples"
   ],
   "id": "879592a01b992193",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(output)",
   "id": "e3bde417310edbb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "d1ecbb235746e422"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ],
   "id": "db6b5052f5cdd980",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_single_neuron(input_dim, activation='relu'):\n",
    "    model = models.Sequential([\n",
    "        # Dense layer with 1 unit, bias included\n",
    "        layers.Dense(1,\n",
    "                     activation=activation,\n",
    "                     input_shape=(input_dim,))\n",
    "    ])\n",
    "    return model"
   ],
   "id": "7e4cacf8803ada1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "model = build_single_neuron(input_dim=10, activation='tanh')\n",
    "preds = model(tf.random.normal((5, 10)))  # batch of 5 samples"
   ],
   "id": "f379f68672a806e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "preds",
   "id": "798c9772961ea892",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Простая полносвязная нейронная сеть\n",
    "\n",
    "Полносвязная нейронная сеть состоит из входного слоя, одного или нескольких скрытых слоев (каждый нейрон соединен с каждым нейроном в соседних слоях) и выходного слоя. Слоистая структура с нелинейными активациями позволяет сети могут аппроксимировать сложные функции.\n",
    "* Для скрытых слоев выбирают нелинейную функцию активации (например, ReLU).\n",
    "* Выходной слой и функция потерь зависят от задачи:\n",
    "    * Классификация (двоичная/многоклассовая): Softmax (многоклассовая) или Sigmoid (двоичная); функция потерь -- кросс-энтропия\n",
    "    * Регрессия: конечная(ыe) функция(и) активации линейная(ые); функция потерь = MSE"
   ],
   "id": "894480f3f0fb96b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "f6f016fa0e14b43c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ── Classification ──\n",
    "class FCNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        # Sequential: Linear → ReLU → Linear (logits)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),                       # hidden activation\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "            # no Softmax here: CrossEntropyLoss expects raw logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "d985a5a933d24d0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "model = FCNNClassifier(input_dim=20, hidden_dim=50, num_classes=3)\n",
    "logits = model(torch.randn(8, 20))                   # batch of 8\n",
    "loss = nn.CrossEntropyLoss()(logits, torch.randint(0, 3, (8,)))"
   ],
   "id": "154e5b959f7cf510",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ── Regression ──\n",
    "class FCNNRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Sequential: Linear → ReLU → Linear (output)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),                       # hidden activation\n",
    "            nn.Linear(hidden_dim, 1)         # single continuous output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "4c8891e9f9425571",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "model = FCNNRegressor(input_dim=20, hidden_dim=50)\n",
    "preds = model(torch.randn(8, 20))                   # batch of 8\n",
    "loss = nn.MSELoss()(preds, torch.randn(8, 1))"
   ],
   "id": "6f89667d3c05b691",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "82b0f092b832aac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# ── Classification ──\n",
    "def build_fcnn_classifier(input_dim, hidden_units, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(num_classes, activation='softmax')  # multi-class probabilities\n",
    "    ])\n",
    "    # Compile with optimizer and categorical cross-entropy\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ],
   "id": "c6b5b5f0011ba153",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "clf = build_fcnn_classifier(input_dim=20, hidden_units=50, num_classes=3)\n",
    "clf.summary()"
   ],
   "id": "f26f2b56f4df700b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ── Regression ──\n",
    "def build_fcnn_regressor(input_dim, hidden_units):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(1)  # linear activation by default\n",
    "    ])\n",
    "    # Compile with optimizer and MSE loss\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n"
   ],
   "id": "c69f45566ee5707b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "reg = build_fcnn_regressor(input_dim=20, hidden_units=50)\n",
    "reg.summary()"
   ],
   "id": "b974afbe1a7652e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Процесс обучения FCNN. Метод обратного распространения ошибки. Градиентный спуск и его вариации. Стратегии инициализации параметров. Эпохи. Скорость обучения\n",
    "\n",
    "#### Общий процесс обучения\n",
    "1.\tПрямой проход\n",
    "    * Входной батч → сеть → выход\n",
    "2.\tВычисление потерь\n",
    "    * Вычисление расхождения между прогнозами и таргетами с помощью функции потерь (например, кросс-энтропии или MSE)\n",
    "3. Обратный проход (обратное распространение)\n",
    "    * Вычисление градиентов потерь по каждому параметру с помощью chain rule\n",
    "4.\tОбновление параметров (градиентный спуск)\n",
    "    * Корректировка весов/смещений с помощью градиентов и скорости обучения\n",
    "5.\tПовторить предыдущие 4 пункта на каждом батче и эпохе, пока не сойдется или не остановимся по другим критериям\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Метод обратного распространения ошибки\n",
    "* Цель: вычислить $\\frac{\\partial L}{\\partial w_{ij}}$ для каждого $w_{ij}$.\n",
    "* Chain rule (цепочки производных):\n",
    "$\\frac{\\partial L}{\\partial w_{ij}} = \\frac{\\partial L}{\\partial z_j}\\;\\frac{\\partial z_j}{\\partial w_{ij}}\n",
    "\\quad\\text{где}\\quad z_j = \\sum_i w_{ij} a_i + b_j$\n",
    "\n",
    "Процесс:\n",
    "\n",
    "1.\tНа выходном слое, $\\delta^{(L)} = \\nabla_{a} L \\odot \\phi{\\prime}(z)$\n",
    "\n",
    "2.\tНа каждом предыдущем слое $l$: $\\delta^{(l)} = (W^{(l+1)})^\\top \\delta^{(l+1)} \\odot \\phi{\\prime}(z^{(l)})$\n",
    "\n",
    "3.\tГрадиенты: $\\nabla_{W^{(l)}} L = \\delta^{(l)} (a^{(l-1)})^\\top,\\quad \\nabla_{b^{(l)}} L = \\delta^{(l)}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Вариации градиентного спуска\n",
    "* Пакетный (Batch GD)\n",
    "    * Использует всю обучающую выборку для вычисления градиентов на каждом шаге\n",
    "    * Стабильный, но медленный и затратный по памяти\n",
    "* Стохастический (SGD)\n",
    "    * Прогон по одному примеру\n",
    "    * Зашумленный обновления весов позволяют избежать локальных минимумов\n",
    "    * Процесс обучения не стабилен и сильно зависит от кол-ва шума в исходных данных\n",
    "* Мини-пакетный (Mini batch GD)\n",
    "    * Компромисс: использование небольших партий (32-256 образцов) исходной выборки\n",
    "    * Распространен на практике для повышения эффективности и стабильности\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Стратегии инициализации параметров\n",
    "* Инициализация нулями\n",
    "    * Плохо: симметричные веса выучивают одни и те же зависимости\n",
    "* Нормальное/равномерное равномерное\n",
    "    * Ломает симметрию, но на практике важна дисперсия\n",
    "* Xavier/Glorot\n",
    "$$\\mathrm{Var}(w) = \\frac{2}{n_\\text{in}+n_\\text{out}}$$\n",
    "    хорошо для tanh/sigmoid\n",
    "* He (Kaiming)\n",
    "$$\\mathrm{Var}(w) = \\frac{2}{n_\\text{in}}$$\n",
    "    хорошо для ReLU\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Эпохи и скорость обучения\n",
    "* Эпоха: один полный прогон обучающей выборки\n",
    "* Скорость обучения (Learning rate)\n",
    "    * Отвечает за размер шага градиентного спуска: слишком большой → рискуем пропустить минимум; слишком маленький → медленно\n",
    "    * Обычно скорость обучения уменьшают с увеличением количества пройденных эпох"
   ],
   "id": "b166c872d57cfbb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "861865d02e687c94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assume MyDataset yields (features, labels)\n",
    "train_ds = MyDataset(...)\n",
    "loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "model = FCNNClassifier(input_dim=..., hidden_dim=..., num_classes=...)"
   ],
   "id": "6cf7e5ef12ee96b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Xavier init for all Linear layers\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()            # classification loss\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.01,                                   # initial learning rate\n",
    "    momentum=0.9\n",
    ")\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()                             # set training mode\n",
    "    total_loss = 0.0\n",
    "    for X, y in loader:                       # mini-batch loop\n",
    "        optimizer.zero_grad()                 # zero gradients\n",
    "        logits = model(X)                     # forward pass\n",
    "        loss = criterion(logits, y)           # compute loss\n",
    "        loss.backward()                       # backpropagation\n",
    "        optimizer.step()                      # update parameters\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "    avg_loss = total_loss / len(train_ds)\n",
    "    print(f\"Epoch {epoch:2d}, Loss: {avg_loss:.4f}\")"
   ],
   "id": "f2b13e86641badfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "fd22362c26b4128b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Prepare dataset\n",
    "train_ds = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "            .shuffle(1000)\n",
    "            .batch(64))\n",
    "\n",
    "model = build_fcnn_classifier(input_dim=..., hidden_units=..., num_classes=...)\n",
    "# He initialization applied by default for 'relu' Dense layers in Keras"
   ],
   "id": "eacd9de0a574aebd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compile with SGD optimizer\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train for a fixed number of epochs\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=20,\n",
    "    verbose=2\n",
    ")"
   ],
   "id": "946add472b0687a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Обучение глубоких FCNN. Проблема исчезающего градиента (vanishing gradient problem). Проблема взрывающегося градиента (exploding gradient problem). Методы регуляризации. Методы увеличения стабильности сети.\n",
    "\n",
    "#### Исчезающие и Взрывающиеся Градиента\n",
    "* Проблема исчезающего градиента возникает, когда частные производные в методе обратного распространения уменьшаются экспоненциально при переходе от слоя к слою - это характерно для sigmoid/tanh ФА - и слои, расположенные ближе к началу, обучаются очень медленно.\n",
    "* Проблема взрывающегося градиента возникает, когда производные очень быстро растут, что приводит к нестабильному обновлению и переполнению параметров.\n",
    "\n",
    "#### Методы регуляризации\n",
    "* L2 weight decay: добавка $\\lambda\\|\\mathbf W\\|^2$ к loss функции, препятствует весам быть большими.\n",
    "* Dropout: случайным образом зануляет активации при обучении для предотвращения ко-адаптации.\n",
    "* Early stopping (ранняя остановка): завершает процесс обучения, когда loss не уменьшается какое-то время\n",
    "\n",
    "#### Методы увеличения стабильности сети\n",
    "* Качественная инициализация весов (Xavier для tanh/sigmoid, He для ReLU) для поддержки стабильности дисперсии.\n",
    "* Batch Normalization (или LayerNorm): нормализует входы слоя (mean=0, var=1), сглаживая оптимизируемую поверхность.\n",
    "* Gradient clipping (подрезка градиентов): зафиксировать рамки градиентов для предотвращения проблемы взрывающихся градиентов.\n",
    "* Residual connections: дополнительные связи между слоями, чтобы градиенты могли проходить беспрепятственно.\n",
    "* Использование ReLU (или его вариантов) для предотвращения исчезновения градиентов."
   ],
   "id": "c129d00780635a92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "9a4489d61d8ed00f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DeepFCNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, num_classes, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h in hidden_dims:\n",
    "            # Linear → BatchNorm → ReLU → Dropout\n",
    "            layers += [\n",
    "                nn.Linear(prev_dim, h),\n",
    "                nn.BatchNorm1d(h),             # stabilizes activations\n",
    "                nn.ReLU(inplace=True),         # non-saturating activation\n",
    "                nn.Dropout(p=dropout_p)        # regularization\n",
    "            ]\n",
    "            prev_dim = h\n",
    "        layers.append(nn.Linear(prev_dim, num_classes))  # output layer\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        # He init for all Linear layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "d5b8a3f1d9978f2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ── Training with gradient clipping ──\n",
    "model = DeepFCNN(input_dim=100,\n",
    "                 hidden_dims=[256, 256, 128],\n",
    "                 num_classes=10,\n",
    "                 dropout_p=0.5)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=1e-3,         # learning rate\n",
    "                              weight_decay=1e-4)  # L2 regularization\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)              # forward\n",
    "        loss = criterion(logits, y_batch)    # compute loss\n",
    "        loss.backward()                      # backpropagate\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # clip gradients to max norm=1.0\n",
    "        optimizer.step()                     # update\n",
    "    # ... validation & early stopping ..."
   ],
   "id": "e4bf56cd708dd483",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "1516ff7c59e397bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_deep_fcnn(input_dim, hidden_units, num_classes, dropout_p=0.5):\n",
    "    model = Sequential()\n",
    "    for h in hidden_units:\n",
    "        model.add(Dense(\n",
    "            h,\n",
    "            activation=None,\n",
    "            kernel_initializer='he_normal',      # He init for ReLU\n",
    "            kernel_regularizer=l2(1e-4),         # L2 regularization\n",
    "            input_shape=(input_dim,) if model.layers==[] else None\n",
    "        ))\n",
    "        model.add(BatchNormalization())          # stabilize activations\n",
    "        model.add(tf.keras.layers.ReLU())        # non-saturating activation\n",
    "        model.add(Dropout(dropout_p))            # regularization\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ],
   "id": "61f0e007a7ad906f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = build_deep_fcnn(input_dim=100,\n",
    "                        hidden_units=[256, 256, 128],\n",
    "                        num_classes=10,\n",
    "                        dropout_p=0.5)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3,\n",
    "                                     clipnorm=1.0)   # gradient clipping\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(train_ds,\n",
    "          epochs=50,\n",
    "          validation_data=val_ds,\n",
    "          callbacks=[early_stop])"
   ],
   "id": "4217dcf476f985cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Оптимизаторы\n",
    "\n",
    "1. Stochastic Gradient Descent (SGD)\n",
    "    * Как обновляется: $w_{t+1} = w_t - \\eta \\,\\nabla_w L(w_t)$\n",
    "    * Простой, не требует много памяти\n",
    "\t* Медленно сходится, чувствителен к сложным поверхностям\n",
    "\t* Гиперпараметры: learning rate\n",
    "2. SGD + Momentum\n",
    "    * Мотивация: накапливать вектор скорости для сглаживания обновлений и ускорения при обновлениях в одном направлении.\n",
    "\t* Как обновляется: $v_{t+1} = \\mu\\,v_t - \\eta\\,\\nabla_w L(w_t),\\quad w_{t+1} = w_t + v_{t+1}$\n",
    "\t* Быстрее сходится, меньше колеблется\n",
    "\t* Добавляется еще один гиперпараметр (momentum $μ$)\n",
    "3. Nesterov Accelerated Gradient (NAG)\n",
    "\t* Вычисляет градиент в приблизительной будущей точке\n",
    "\t* Как обновляется: $v_{t+1} = \\mu\\,v_t - \\eta\\,\\nabla_w L(w_t + \\mu\\,v_t),\\quad w_{t+1} = w_t + v_{t+1}$\n",
    "\t* Обычно быстрее чем ванильный моментум\n",
    "\t* Те же гиперпараметры, что и у моментума\n",
    "4. AdaGrad\n",
    "\t* Идея: адаптировать скорость обучения каждого параметра на основе их прошлых градиентов.\n",
    "\t* Как обновляется: $r_t = r_{t-1} + (\\nabla_w L(w_t))^2,\\quad w_{t+1} = w_t - \\frac{\\eta}{\\sqrt{r_t + \\epsilon}}\\,\\nabla_w L(w_t)$\n",
    "\t* Круто для разреженных фичей\n",
    "\t* Скорость обучения уменьшается слишком агрессивно\n",
    "5. RMSProp\n",
    "\t* Допиленный адаград: использует экспоненциальное скользящее среднее квадратов градиентов.\n",
    "\t* Как обновляется: $r_t = \\rho\\,r_{t-1} + (1-\\rho)(\\nabla_w L)^2,\\quad w_{t+1} = w_t - \\frac{\\eta}{\\sqrt{r_t + \\epsilon}}\\,\\nabla_w L$\n",
    "\t* Более стабильный learnin rate\n",
    "\t* Гиперпараметры: decay rate ρ (default 0.9)\n",
    "6. AdaDelta\n",
    "\t* Расширение RMSProp: дополнительно скейлит обновления без необходимости глобального параметра скорости обучения\n",
    "\t* Нет необходимости настраивать learning rate\n",
    "\t* Более вычислительно сложный, по сравнению с RMSProp\n",
    "7. Adam\n",
    "\t* Комбинирует идеи моментума и RMSProp\n",
    "\t* Как обновляется: $m_t = \\beta_1 m_{t-1} + (1-\\beta_1)\\nabla,\\quad v_t = \\beta_2 v_{t-1} + (1-\\beta_2)\\nabla^2$\n",
    "\t  смещение\n",
    "$$\\hat m_t = m_t/(1-\\beta_1^t),\\,\\hat v_t = v_t/(1-\\beta_2^t)$$\n",
    "$$w_{t+1} = w_t - \\eta\\,\\frac{\\hat m_t}{\\sqrt{\\hat v_t} + \\epsilon}$$\n",
    "    * Быстро сходится\n",
    "\t* Гиперпараметры: β₁≈0.9, β₂≈0.999\n",
    "8. AdamW\n",
    "\t* Исключает затухание весов из оценки момента в Adam\n",
    "    * Более сильная L2 регуляризация"
   ],
   "id": "3d434cafa010dc28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "7ee6a204a8cef263"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PyTorch optimizer examples\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. SGD\n",
    "optim.SGD(model.parameters(),\n",
    "          lr=0.01)                                # base SGD\n",
    "\n",
    "# 2. SGD + Momentum\n",
    "optim.SGD(model.parameters(),\n",
    "          lr=0.01,\n",
    "          momentum=0.9)                          # add momentum µ=0.9\n",
    "\n",
    "# 3. Nesterov\n",
    "optim.SGD(model.parameters(),\n",
    "          lr=0.01,\n",
    "          momentum=0.9,\n",
    "          nesterov=True)                        # NAG\n",
    "\n",
    "# 4. AdaGrad\n",
    "optim.Adagrad(model.parameters(),\n",
    "              lr=0.01,\n",
    "              eps=1e-8)                          # per‐param adaptivity\n",
    "\n",
    "# 5. RMSProp\n",
    "optim.RMSprop(model.parameters(),\n",
    "              lr=0.001,\n",
    "              alpha=0.9,                         # decay rate ρ\n",
    "              eps=1e-8)\n",
    "\n",
    "# 6. AdaDelta\n",
    "optim.Adadelta(model.parameters(),\n",
    "               lr=1.0,                             # often default\n",
    "               rho=0.95)\n",
    "\n",
    "# 7. Adam\n",
    "optim.Adam(model.parameters(),\n",
    "           lr=0.001,\n",
    "           betas=(0.9, 0.999),                   # β₁,β₂\n",
    "           eps=1e-8)\n",
    "\n",
    "# 8. AdamW\n",
    "optim.AdamW(model.parameters(),\n",
    "            lr=0.001,\n",
    "            betas=(0.9, 0.999),\n",
    "            weight_decay=1e-2)                  # decoupled L2"
   ],
   "id": "6e5a9ecae660d620",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "ac9813811f46a517"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TensorFlow (Keras) optimizer examples\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. SGD\n",
    "tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# 2. SGD + Momentum\n",
    "tf.keras.optimizers.SGD(learning_rate=0.01,\n",
    "                        momentum=0.9)\n",
    "\n",
    "# 3. Nesterov\n",
    "tf.keras.optimizers.SGD(learning_rate=0.01,\n",
    "                        momentum=0.9,\n",
    "                        nesterov=True)\n",
    "\n",
    "# 4. AdaGrad\n",
    "tf.keras.optimizers.Adagrad(learning_rate=0.01,\n",
    "                            epsilon=1e-8)\n",
    "\n",
    "# 5. RMSProp\n",
    "tf.keras.optimizers.RMSprop(learning_rate=0.001,\n",
    "                            rho=0.9,\n",
    "                            epsilon=1e-8)\n",
    "\n",
    "# 6. AdaDelta\n",
    "tf.keras.optimizers.Adadelta(learning_rate=1.0,\n",
    "                             rho=0.95)\n",
    "\n",
    "# 7. Adam\n",
    "tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "                         beta_1=0.9,\n",
    "                         beta_2=0.999,\n",
    "                         epsilon=1e-8)\n",
    "\n",
    "# 8. AdamW\n",
    "tf.keras.optimizers.experimental.AdamW(learning_rate=0.001,\n",
    "                                       weight_decay=1e-2)"
   ],
   "id": "2b75547c0b4934bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Мониторинг процесса обучения на валидационной выборке\n",
    "\n",
    "Зачем?\n",
    "* Обнаружение переобучения: лосс на валидационной выборке растет, в то время когда на обучающей падает\n",
    "* Ранняя остановка: остановиться, когда лосс на валидационной перестает падать\n",
    "* Настройка гиперпараметров: выбор скорости обучения, архитектуры модели и регуляризации"
   ],
   "id": "f704c669d52432a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "315eb5f7236758bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume model, criterion, optimizer defined; train_loader & val_loader ready\n",
    "history = {'train_loss':[], 'val_loss':[], 'val_acc':[]}\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    # ——— Training ———\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X,y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "    history['train_loss'].append(running_loss/len(train_loader.dataset))\n",
    "\n",
    "    # ——— Validation ———\n",
    "    model.eval()\n",
    "    val_loss, all_preds, all_targets = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            logits = model(Xv)\n",
    "            val_loss += criterion(logits, yv).item() * Xv.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(yv.cpu())\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    # Compute validation accuracy\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    acc = accuracy_score(all_targets, all_preds)  # Or another metrics\n",
    "    history['val_acc'].append(acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={history['train_loss'][-1]:.4f}, \"\n",
    "          f\"val_loss={val_loss:.4f}, val_acc={acc:.4f}\")\n",
    "\n",
    "# ——— Plotting ———\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.figure()                                      # Loss curves\n",
    "plt.plot(epochs, history['train_loss'], label='Train')\n",
    "plt.plot(epochs, history['val_loss'],   label='Val')\n",
    "plt.title('Loss vs. Epoch'); plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "plt.figure()                                      # Accuracy curve\n",
    "plt.plot(epochs, history['val_acc'], label='Val Acc')\n",
    "plt.title('Val Accuracy vs. Epoch'); plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "plt.legend(); plt.show()"
   ],
   "id": "1a1bafa429d3be75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "10dc4e21ca647f12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "# Assume model built and compiled with metrics=['accuracy']\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=num_epochs,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ——— Plotting ———\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss vs. Epoch'); plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Accuracy vs. Epoch'); plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "# ——— Additional Metrics ———\n",
    "# Compute ROC AUC on validation set\n",
    "y_true, y_pred_probs = [], []\n",
    "for Xv, yv in val_ds:\n",
    "    y_true.append(yv.numpy())\n",
    "    y_pred_probs.append(model.predict(Xv))\n",
    "\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred_probs = np.concatenate(y_pred_probs)\n",
    "# If multiclass, average='macro', multi_class='ovr'\n",
    "print(\"ROC AUC:\", roc_auc_score(y_true, y_pred_probs))\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix'); plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.colorbar(); plt.show()"
   ],
   "id": "779f49489bb96315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Также можно использовать тулзу под названием TensorBoard\n",
    "PyTorch: torch.utils.tensorboard.SummaryWriter\n",
    "Keras: передать колбэк TensorBoard в model.fit(...) для автоматического логгирования всего что вам хочется."
   ],
   "id": "d1b7ef45081d87bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Инференс и использования FCNN\n",
    "\n",
    "#### Режим инференса и подготовка модели\n",
    "1. Включить режим инференса, чтобы слои Dropout, BatchNorn и другие вели себя детерминистично:\n",
    "\t* В PyTorch: `model.eval()`\n",
    "\t* В Keras: модели всегда в готовом для инференса состоянии после вызова model.compile() или load_model()\n",
    "2. Выключить отслеживание градиентов для ускорения инференса и сохранения памяти:\n",
    "\t* В PyTorch: обернуть `forward()` в `with torch.no_grad():`\n",
    "\t* В Keras: `.predict()` делает это автоматически\n",
    "\n",
    "\n",
    "#### Подготовка входных данных для инференса\n",
    "1. Препроцессить фичи **точно так же** как и при обучении"
   ],
   "id": "c27720d246eadeca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "da59d04bae219def"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# 0. Save only the state dict (recommended)\n",
    "torch.save(model.state_dict(), 'fcnn_classifier.pth')\n",
    "\n",
    "# 1. Load model architecture & weights\n",
    "model = FCNNClassifier(input_dim=20, hidden_dim=50, num_classes=3)\n",
    "state = torch.load('fcnn_classifier.pth', map_location='cpu')  # or 'cuda'\n",
    "model.load_state_dict(state)                                   # load trained parameters\n",
    "model.eval()                                                   # set eval mode\n",
    "\n",
    "# 2. Prepare new data\n",
    "# Suppose new_sample is a NumPy array of shape (20,)\n",
    "import numpy as np\n",
    "new_sample = np.random.rand(20).astype(np.float32)             # dummy data\n",
    "# Normalize same way as training data\n",
    "mean, std = 0.5, 0.2                                           # example values\n",
    "new_sample = (new_sample - mean) / std\n",
    "\n",
    "# 3. Convert to tensor & batch\n",
    "input_tensor = torch.from_numpy(new_sample).unsqueeze(0)       # shape (1,20)\n",
    "\n",
    "# 4. Forward pass\n",
    "with torch.no_grad():\n",
    "    logits = model(input_tensor)                               # raw scores\n",
    "    probs  = torch.softmax(logits, dim=1)                      # probabilities\n",
    "    class_idx = torch.argmax(probs, dim=1).item()              # predicted class\n",
    "\n",
    "print(f\"Predicted class: {class_idx}, Probabilities: {probs.squeeze().tolist()}\")"
   ],
   "id": "fb8ed3f63d285b2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "63db02fcfd5f6e27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 0. Save the full model (architecture + weights + optimizer state)\n",
    "model.save('fcnn_model')\n",
    "\n",
    "# 1. Load the saved model\n",
    "model = tf.keras.models.load_model('fcnn_model')\n",
    "\n",
    "# 2. Prepare new data\n",
    "new_sample = np.random.rand(20).astype('float32')              # dummy input\n",
    "# Normalize with training mean/std\n",
    "mean, std = 0.5, 0.2                                           # example\n",
    "new_sample = (new_sample - mean) / std\n",
    "\n",
    "# 3. Batch dimension\n",
    "input_batch = np.expand_dims(new_sample, axis=0)               # shape (1,20)\n",
    "\n",
    "# 4. Predict\n",
    "probs = model.predict(input_batch)                             # shape (1, num_classes)\n",
    "class_idx = np.argmax(probs, axis=1)[0]                        # predicted class\n",
    "\n",
    "print(f\"Predicted class: {class_idx}, Probabilities: {probs[0].tolist()}\")"
   ],
   "id": "3016ec15bd9c7f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Если у вас есть ускоритель\n",
    "\n",
    "В PyTorch, перенести модель и данные на GPU через `.to('cuda')` перед инференсом\n",
    "В Keras, большие батчи автоматом используют все доступные GPU"
   ],
   "id": "4c0504c8cd61995b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Сверточные нейронные сети",
   "id": "8e5e4683058eb94c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Основы\n",
    "\n",
    "CNN обрабатывает структурированные данные (чаще всего изображения и видео), заменяя полносвязанные слои сверточными, использующими пространственную локальность и совместное использование параметров.\n",
    "\n",
    "1. Сверточный слой\n",
    "\t* Применяет обучаемые ядра (фильтры) к локальным рецептивным полям\n",
    "\t* Создает карты признаков: каждый фильтр обнаруживает определенный паттерн (края, текстуры)\n",
    "\t* Параметр `stride` управляет размером шага; параметр `padding` сохраняет пространственные размеры\n",
    "2. Активация\n",
    "\t* Нелинейная функция (ReLU, LeakyReLU) применяется поэлементно к картам признаков\n",
    "3. Слой Pooling\n",
    "\t* Уменьшение размерности признакового пространства с помощью max/avg.\n",
    "\t* Уменьшает вычислительную сложность\n",
    "4. Слоистая структура\n",
    "\t* Более ранние слои фиксируют низкоуровневые характеристики (края); более глубокие слои фиксируют высокоуровневые концепты (отдельные объекты)\n",
    "5. Выпрямление и FCNN\n",
    "\t* Итоговые карты признаков выпрямляются и проходят через полносвязные слои для задач классификации, регрессии или других"
   ],
   "id": "486361f4a48b2378"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "73102ba80e1d3c8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # Convolution: in_channels=3 (RGB), out_channels=16, kernel_size=3×3\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        # Convolution: 16 → 32 feature maps\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        # Max pooling with 2×2 window\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully connected: flatten 32×8×8 → 128 neurons\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        # Output layer: 128 → num_classes\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # conv1 → ReLU → pool ⇒ output size: 16×16×16\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # conv2 → ReLU → pool ⇒ output size: 32×8×8\n",
    "        x = x.view(x.size(0), -1)             # flatten feature maps\n",
    "        x = F.relu(self.fc1(x))               # fully connected + ReLU\n",
    "        x = self.fc2(x)                       # final logits\n",
    "        return x"
   ],
   "id": "406d63379a5c5481",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "model = SimpleCNN(num_classes=10)\n",
    "imgs = torch.randn(4, 3, 32, 32)       # batch of 4 RGB 32×32 images\n",
    "logits = model(imgs)"
   ],
   "id": "496d0c31ea7054bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "71ce0c01887f49ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_simple_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
    "    model = models.Sequential([\n",
    "        # Conv2D: 16 filters of size 3×3, padding='same'\n",
    "        layers.Conv2D(16, (3, 3), padding='same', activation='relu',\n",
    "                      input_shape=input_shape),\n",
    "        # MaxPooling2D: downsample by factor of 2\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        # Conv2D: 32 filters of size 3×3\n",
    "        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        # Flatten feature maps to vector\n",
    "        layers.Flatten(),\n",
    "        # Dense hidden layer with 128 units\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        # Output layer with softmax for classification\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ],
   "id": "75d56808b40a95ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "model = build_simple_cnn((32, 32, 3), 10)\n",
    "model.summary()"
   ],
   "id": "34861cb4743db493",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pooling\n",
    "\n",
    "\n",
    "Cлои Pooling выполняют понижающую дискретизацию карт признаков, обобщая локальные окрестности, уменьшая пространственные размеры, сложность вычислений и (в некоторой степени) переобучение.\n",
    "\n",
    "| Pooling Type | Operation                                          | Use Case & Properties                                                                                      |\n",
    "| ------------ |----------------------------------------------------|------------------------------------------------------------------------------------------------------------|\n",
    "| Max Pooling | $\\max$ over each $k\\times k$ window                | Captures strongest activation; preserves salient features (edges, corners); common default.                |\n",
    "| Average Pooling | Mean over each $k\\times k$ window                  | Smooths activations; retains background context; sometimes used in regression or heatmap tasks.            |\n",
    "| Global Average/Max | Pool over entire spatial dims -> scalar per channel | Aggressive downsampling to $1\\times 1$; often before FC layers; reduces parameters; used in classification. |\n",
    "| Adaptive Pooling | Output to a specified spatial size | Guarantees fixed output regardless of input size; useful for variable-resolution inputs. |\n"
   ],
   "id": "863bf75929638cd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "57e81e24c43068e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. Local Max Pooling (2×2 window, stride 2)\n",
    "max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# 2. Local Average Pooling (2×2 window, stride 2)\n",
    "avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# 3. Global Average Pooling → output size = (1,1)\n",
    "global_avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "# 4. Global Max Pooling → output size = (1,1)\n",
    "global_max = nn.AdaptiveMaxPool2d((1, 1))\n",
    "\n",
    "# Example forward usage in a nn.Module:\n",
    "class PoolingDemo(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x1 = max_pool(x)              # strong activations\n",
    "        x2 = avg_pool(x)              # smoothed activations\n",
    "        x3 = global_avg(x).view(x.size(0), -1)  # flatten to (batch, channels)\n",
    "        return x1, x2, x3"
   ],
   "id": "fadc788111322c9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "f142606d10cf697c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_pooling_demo(input_shape=(32,32,3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # 1. Local Max Pooling\n",
    "    x1 = layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(inputs)\n",
    "\n",
    "    # 2. Local Average Pooling\n",
    "    x2 = layers.AveragePooling2D(pool_size=(2,2), strides=(2,2))(inputs)\n",
    "\n",
    "    # 3. Global Average Pooling → (batch_size, channels)\n",
    "    x3 = layers.GlobalAveragePooling2D()(inputs)\n",
    "\n",
    "    # 4. Global Max Pooling → (batch_size, channels)\n",
    "    x4 = layers.GlobalMaxPooling2D()(inputs)\n",
    "\n",
    "    return models.Model(inputs, [x1, x2, x3, x4])\n",
    "\n",
    "# Example instantiation:\n",
    "model = build_pooling_demo()\n",
    "outputs = model(tf.random.normal((4,32,32,3)))"
   ],
   "id": "eb45ea21f10a26d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Работа с изображениями с разными разрешениями. Padding\n",
    "\n",
    "#### Зачем и когда?\n",
    "1. Сохранить соотношения сторон: Вместо того чтобы растягивать или сжимать изображение, можно добавить padding, чтобы оно соответствовало нужной форме (например, 224×224).\n",
    "2. Предотвратить потерю информации: Кропая изображение можно потерять нужные детали. Паддинг позволяет этого избежать\n",
    "3. Эффективность батчинга: Сети ожидают одинаковые размеры матриц, паддинг позволяет батчить разные изображения вместе.\n",
    "\n",
    "| Тип       | Описание                               | Комментарий                                |\n",
    "|-----------|----------------------------------------|--------------------------------------------|\n",
    "| Zero      | заполнить нулями (черный цвет границы) | может добавить дополнительные края (плохо) |\n",
    "| Reflect   | отразить изображение за границей       | сохраняет текстуры и края                  |\n",
    "| Replicate | повторять последний пиксель на границе | менее жестко, нежели нули                  |\n",
    "| Constant  | заполнить константным цветом           | белый цвет для сканов документов           |"
   ],
   "id": "54f961f274858d52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "c8226ff5ffacf84b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Compute padding amounts for a given image to make it square (e.g. 224×224)\n",
    "def pad_to_square(img, fill=0):\n",
    "    w, h = img.size\n",
    "    max_side = max(w, h)\n",
    "    pad_left = (max_side - w) // 2\n",
    "    pad_right = max_side - w - pad_left\n",
    "    pad_top = (max_side - h) // 2\n",
    "    pad_bottom = max_side - h - pad_top\n",
    "    # transforms.Pad expects (left, top, right, bottom)\n",
    "    return transforms.Pad((pad_left, pad_top, pad_right, pad_bottom), fill=fill)(img)\n",
    "\n",
    "def reflect_pad_to_square(img):\n",
    "    w, h = img.size\n",
    "    max_side = max(w, h)\n",
    "    pads = [(max_side - w) // 2, (max_side - h) // 2,\n",
    "            max_side - w - (max_side - w)//2, max_side - h - (max_side - h)//2]\n",
    "    return F.pad(img, pads, padding_mode='reflect')\n",
    "\n",
    "# 2. Compose a transform: pad → resize → to tensor → normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: pad_to_square(img, fill=128)),  # gray padding. Or use reflect_pad_to_square\n",
    "    transforms.Resize((224, 224)),                                # final size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# Usage in a Dataset\n",
    "class MyImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ],
   "id": "47ce3ef815ee41b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "6b76796a2f48dbd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def pad_to_square_tf(image, pad_value=0):\n",
    "    # image: [H, W, C]\n",
    "    shape = tf.shape(image)[:2]\n",
    "    h, w = shape[0], shape[1]\n",
    "    max_side = tf.maximum(h, w)\n",
    "    pad_h = max_side - h\n",
    "    pad_w = max_side - w\n",
    "    pad_top = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "    pad_left = pad_w // 2\n",
    "    pad_right = pad_w - pad_left\n",
    "    # paddings: [[top, bottom], [left, right], [0,0]]\n",
    "    paddings = [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]]\n",
    "    return tf.pad(image, paddings, constant_values=pad_value)\n",
    "\n",
    "# Build a preprocessing layer\n",
    "def build_preprocessing_layer(target_size=(224,224), pad_value=128):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Lambda(lambda img: pad_to_square_tf(img, pad_value)),\n",
    "        tf.keras.layers.Resizing(target_size[0], target_size[1]),\n",
    "        tf.keras.layers.Rescaling(1./255),\n",
    "        tf.keras.layers.Normalization(mean=[0.485,0.456,0.406],\n",
    "                                      variance=[0.229**2,0.224**2,0.225**2])\n",
    "    ])\n",
    "\n",
    "# Usage in tf.data pipeline\n",
    "preproc = build_preprocessing_layer()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(list_of_paths)\n",
    "dataset = dataset.map(lambda path: tf.io.read_file(path)\n",
    "                                 .pipe(tf.image.decode_jpeg, channels=3)\n",
    "                                 .pipe(lambda img: preproc(img)))"
   ],
   "id": "e08786b2e2748500",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Регуляризация в CNN\n",
    "\n",
    "\n",
    "1.\tWeight Decay (L2 Regularization)\n",
    "\t*\tШтрафует веса, если они слишком большие, добавляя $\\lambda \\|\\mathbf W\\|^2$ к лосс функции\n",
    "\t*\tУже написано за вас в оптимизаторах (`weight_decay`, `kernel_regularizer=l2`)\n",
    "2. Spatial Dropout / DropBlock\n",
    "\t* SpatialDropout зануляет карты признаков (каналы) целиком для увеличения стабильности\n",
    "\t* DropBlock случайным образом маскирует регионы на картах признаков\n",
    "3. Batch Normalization\n",
    "\t* То же самое, что и в FCNN, но 2D\n",
    "4. Аугментация данных\n",
    "\t* Геометрическая: отражения, кропы, повороты\n",
    "\t* Фотометрическая: изменение цветов, изменения контраста\n",
    "5. Label Smoothing\n",
    "\t* Смягчает one-hot таргеты (до 0.9/0.1) для уменьшения \"слишком уверенных\" предсказаний\n",
    "6. Early Stopping\n",
    "    * То же самое, что и в FCNN"
   ],
   "id": "3316e1bdd0fe54a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "3c2f0b549c067935"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# 1. Data augmentation pipeline\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomResizedCrop(224),          # random crop & resize\n",
    "    T.RandomHorizontalFlip(),          # flip left-right\n",
    "    T.ColorJitter(brightness=0.2,\n",
    "                  contrast=0.2,\n",
    "                  saturation=0.2),     # photometric\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406],\n",
    "                std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# 2. Model with BatchNorm and SpatialDropout\n",
    "class CNNWithReg(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(pretrained=False)\n",
    "        # Replace final layer and add dropout\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),      # dropout before FC\n",
    "            nn.Linear(self.backbone.fc.in_features, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = CNNWithReg(num_classes=10)\n",
    "\n",
    "# 3. Loss with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# 4. Optimizer with weight decay\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4             # L2 regularization\n",
    ")\n",
    "\n",
    "# 5. (Optional) implement Cutout in training loop\n",
    "def cutout(x, mask_size=50):\n",
    "    # x: tensor [B,C,H,W]\n",
    "    B, C, H, W = x.shape\n",
    "    y = x.clone()\n",
    "    for i in range(B):\n",
    "        top = torch.randint(0, H-mask_size, ())\n",
    "        left = torch.randint(0, W-mask_size, ())\n",
    "        y[i, :, top:top+mask_size, left:left+mask_size] = 0\n",
    "    return y\n",
    "\n",
    "# Example training step\n",
    "for images, targets in train_loader:\n",
    "    images = cutout(images, mask_size=60)       # optional Cutout\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(images)\n",
    "    loss = criterion(logits, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ],
   "id": "446c0a35e6f32e33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TensorFlow",
   "id": "cbd97d7020def100"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "# 1. Data augmentation layer\n",
    "data_augment = tf.keras.Sequential([\n",
    "    layers.RandomResizedCrop(224, 224),  # crop & resize\n",
    "    layers.RandomFlip('horizontal'),     # flip\n",
    "    layers.RandomRotation(0.1),          # small rotation\n",
    "    layers.RandomContrast(0.2)           # photometric\n",
    "])\n",
    "\n",
    "# 2. Build model with BatchNorm and SpatialDropout\n",
    "def build_cnn_with_reg(num_classes=10):\n",
    "    inputs = layers.Input((224,224,3))\n",
    "    x = data_augment(inputs)                     # augment\n",
    "    x = layers.Rescaling(1./255)(x)\n",
    "    # Pretrained backbone\n",
    "    base = tf.keras.applications.ResNet50(\n",
    "        include_top=False, weights=None, pooling='avg'\n",
    "    )\n",
    "    x = base(x)\n",
    "    x = layers.BatchNormalization()(x)           # regularizing BN\n",
    "    x = layers.SpatialDropout2D(0.3)(tf.expand_dims(tf.expand_dims(x,1),1))\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(\n",
    "        num_classes,\n",
    "        activation='softmax',\n",
    "        kernel_regularizer=regularizers.l2(1e-4) # weight decay\n",
    "    )(x)\n",
    "    return models.Model(inputs, x)\n",
    "\n",
    "model = build_cnn_with_reg(num_classes=10)\n",
    "\n",
    "# 3. Compile with label smoothing\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 4. Early stopping callback\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 5. Fit\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ],
   "id": "b7a7a0e03944f1b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Работа с большими датасетами. Даталоадеры и датасеты. Автоматизация препроцессинга\n",
    "\n",
    "Когда набор данных не помещается в памяти, вам нужен конвейер, который\n",
    "1. Обеспечит потоковое чтение объектов с диска\n",
    "2. Автоматически сделает препроцессинг/аугментацию на лету\n",
    "3. Эффективно организует данные для подачи в нейронную сеть (сформирует батчи и т.д.)\n",
    "\n",
    "И PyTorch, и TensorFlow предоставляют абстракции для автоматизации этой работы."
   ],
   "id": "46242d640128ac66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PyTorch",
   "id": "fad6db29651b9515"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset\n",
    "# Encodes how to load and transform a single example.\n",
    "# Must implement __len__ and __getitem__.\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes                         # e.g. ['cat','dog']\n",
    "        self.transform = transform\n",
    "        # build list of (image_path, label_idx)\n",
    "        self.samples = []\n",
    "        for idx, cls in enumerate(classes):\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            for fname in os.listdir(cls_dir):\n",
    "                if fname.lower().endswith(('.jpg','.png')):\n",
    "                    self.samples.append((os.path.join(cls_dir, fname), idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path, label = self.samples[i]\n",
    "        img = Image.open(path).convert('RGB')          # load from disk\n",
    "        if self.transform:\n",
    "            img = self.transform(img)                  # augment/preprocess\n",
    "        return img, label"
   ],
   "id": "30196b4d7df04e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DataLoader\n",
    "# Wraps the Dataset to provide batching, shuffling, parallel I/O.\n",
    "\n",
    "# 1. Define transforms: augmentation + normalization\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomResizedCrop(224),       # random crop & resize\n",
    "    T.RandomHorizontalFlip(),       # random flip\n",
    "    T.ColorJitter(0.2,0.2,0.2,0.1), # random brightness/contrast/sat/hue\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],\n",
    "                [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# 2. Create Dataset\n",
    "train_ds = ImageFolderDataset(\n",
    "    root_dir='data/train',\n",
    "    classes=['cat','dog'],       # example\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "# 3. Create DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=64,\n",
    "    shuffle=True,                # randomize each epoch\n",
    "    num_workers=4,               # parallel data loading\n",
    "    pin_memory=True              # speed up GPU transfers\n",
    ")\n",
    "\n",
    "# 4. Use in training loop\n",
    "for images, labels in train_loader:\n",
    "    images = images.to(device)   # move to GPU\n",
    "    labels = labels.to(device)\n",
    "    # forward / backward / optimize..."
   ],
   "id": "109222d5cfa1cb5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TensorFlow",
   "id": "97a046d3a4efac5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creating the Dataset\n",
    "# From file paths + labels, or from a directory structure.\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. List file paths & labels\n",
    "import glob\n",
    "file_paths = glob.glob('data/train/*/*.jpg')\n",
    "labels = [0 if 'cat' in p else 1 for p in file_paths]\n",
    "\n",
    "# 2. Create a tf.data.Dataset from tensors\n",
    "ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))"
   ],
   "id": "6824d1a0efdaa2a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Mapping: load, decode, augment, batch\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def load_and_preprocess(path, label):\n",
    "    # Read file, decode JPEG, convert to float32\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # Data augmentation\n",
    "    img = tf.image.random_crop(img, size=[200,200,3])\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    # Resize & normalize\n",
    "    img = tf.image.resize(img, [224,224])\n",
    "    return img, label\n",
    "\n",
    "train_ds = (\n",
    "    ds.shuffle(10000)                    # buffer shuffle\n",
    "      .map(load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "      .batch(64)\n",
    "      .prefetch(AUTOTUNE)                # overlap data prep & model\n",
    ")"
   ],
   "id": "6af331783971ece0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Бест практики\n",
    "\n",
    "1. Parallel I/O:\n",
    "\t* PyTorch → `num_workers>0`\n",
    "\t* TF → `num_parallel_calls=tf.data.AUTOTUNE`\n",
    "2. Prefetching:\n",
    "\t* PyTorch → `prefetch_factor`\n",
    "    * TF → `.prefetch()`\n",
    "3. Caching (for small datasets):\n",
    "    * TF → `.cache()` для избежания выполнения одних и тех же операций\n",
    "4. Mixed Augmentation:\n",
    "    * Выполнение CPU-bound операций (преобразования) в пайплайне датасета\n",
    "    * GPU-bound операции (цвет, блюр) внутри модели model"
   ],
   "id": "f2af958b9d04ab84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Использования GPU\n",
    "\n",
    "Зачем использовать ГПУ?\n",
    "* Массивный параллелизм: Современные GPU имеют тысячи ядер, оптимизированных для выполнения одной и той же арифметической операции над большими массивами (например, матричные умножения, свертки), что дает ускорение на порядки по сравнению с CPU.\n",
    "* Высокая пропускная способность памяти: GPU гораздо быстрее перемещают данные в память устройства и из нее, уменьшая ботлнек ввода-вывода при обработке больших тензоров.\n",
    "* Сокращение времени обучения: Более быстрые итерации позволяют больше экспериментировать, использовать большие модели или большие батчи и обучаться за часы, а не за дни."
   ],
   "id": "66ae58b69ed110eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PyTorch",
   "id": "1a0f5d460729af43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Select device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2. Instantiate model and move to GPU\n",
    "model = FCNNClassifier(input_dim=20, hidden_dim=50, num_classes=3)\n",
    "model.to(device)  # all parameters + buffers moved\n",
    "\n",
    "# 3. Prepare data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 4. Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        # move batch to GPU\n",
    "        X = X.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)         # compute on GPU\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()           # gradients on GPU\n",
    "        optimizer.step()"
   ],
   "id": "1ba2a241e9da281a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TensorFlow",
   "id": "cd3d39235a74c29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. List available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs:\", gpus)\n",
    "\n",
    "# 2. (Optional) Set memory growth to avoid allocating all GPU memory\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# 3. Build and compile model as usual\n",
    "model = build_fcnn_classifier(input_dim=20, hidden_units=50, num_classes=3)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. Fit — Keras will automatically use all available GPUs\n",
    "history = model.fit(train_ds, epochs=10, batch_size=64)"
   ],
   "id": "2282f706e789a254",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ade01b008e61a5ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4fd0100cf58ddf10",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
